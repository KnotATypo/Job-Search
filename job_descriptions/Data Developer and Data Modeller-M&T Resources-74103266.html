<div class="y735df0 _1pehz540">
 Our client is undertaking a digital transformation towards becoming a utility of the future.
 <br/>
 <br/>
 <strong>
  Data Developer:
 </strong>
 <br/>
 <br/>
 <strong>
  The position requirements are as follows:
 </strong>
 <br/>
 <ul>
  <li>
   Evolve Enterprise Data Platform (EDP) which is a cloud-based, large-scale data and intelligence solution that is customer focused, easy to consume and create business impact.
  </li>
  <li>
   Actively participate in data engineering initiatives and build end-to-end analytical solutions that are highly available, scalable, stable, secure, and cost-effective.
  </li>
  <li>
   Comply with standards, data security / privacy obligations, quality rules and the Information Management Framework.
  </li>
  <li>
   Implement and test data ingest pipelines to support unstructured, semi-structured and structured data.
  </li>
  <li>
   Collaborate effectively with project team members and contribute to knowledge sharing and up-skilling of the Enterprise Intelligence team.
  </li>
 </ul>
 <strong>
  Selection Criteria
 </strong>
 :
 <br/>
 <ul>
  <li>
   Demonstrated experience in designing, implementing, and operating large-scale, high-volume, high-performance data solutions for analytics and data science.
  </li>
  <li>
   Demonstrated experience in implementing data ingestion routines both real time and batch by leveraging modern technologies such as AWS, Azure, Python, Databricks and PowerBI
  </li>
  <li>
   Demonstrated experience in building and maintaining secure, reliable, and scalable infrastructure and services on AWS
  </li>
  <li>
   Experience working in an agile project environment
  </li>
  <li>
   Knowledge and demonstrated application of data management principles and best practices.
  </li>
 </ul>
 <strong>
  Data Modeller:
  <br/>
  <br/>
 </strong>
 <strong>
  The position requirements are as follows:
 </strong>
 <br/>
 <ul>
  <li>
   Evolve Enterprise Data Platform (EDP) which is a cloud-based, large-scale data and intelligence solution that is customer focused, easy to consume and create business impact.
  </li>
  <li>
   Contribute to the uplift of data modelling practices, standards, approaches and tooling.
  </li>
  <li>
   Develop designs for enterprise data models, data pipelines and analytic models.
  </li>
  <li>
   Participate in the evolution of data management practices standards, data modelling approaches, naming conventions, data quality and metadata management.
  </li>
 </ul>
 <strong>
  <strong>
   Selection Criteria:
   <br/>
  </strong>
 </strong>
 <ul>
  <li>
   Demonstrated experience in developing and implementing enterprise data models leveraging approaches and architectures such as Data Vault, Kimball and ER modelling
  </li>
  <li>
   Demonstrated experience in designing and establishing data pipelines that are secure, large-scale, high-volume, cost-effective and high-performance for structured, unstructured and semi-structured data
  </li>
  <li>
   Translation of requirements into solution designs with a focus on delivering customer value and outcomes. Definition of technical business rules, source-to-target mappings and data models.
  </li>
  <li>
   Knowledge and demonstrated experience using modern software development approaches and technologies, including but not limited to automation, code management and CI/CD
  </li>
 </ul>
 For more information about this role please contact Carol Ferraz at
 <a data-contact-match="true" href="/cdn-cgi/l/email-protection#4d2e2c3f2221632b283f3f2c370d20393f632e2220632c38">
  <span class="__cf_email__" data-cfemail="4d2e2c3f2221632b283f3f2c370d20393f632e2220632c38">
   [emailÂ protected]
  </span>
 </a>
 or
 <a data-contact-match="true" href="tel:07 3215 7222">
  07 3215 7222
 </a>
</div>
